{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import emcee as mc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createMockCluster(rin,rout,nmean,k,smax,m,vmean,threeD=False):\n",
    "    ntot = np.random.poisson(lam=nmean)\n",
    "    \n",
    "    nu0 = ntot/(4*np.pi*(np.log(rout/rin))) if k==3. else ntot*(3.-k)/(4*np.pi*(rout**(3.-k)-rin**(3.-k)))\n",
    "    #rho = 4*np.pi*nu0*np.random.uniform(low=rin,high=rout,size=ntot)**(2.-k)\n",
    "    rho = np.power(np.random.uniform(4*np.pi*nu0*rin**(2.-k),4*np.pi*nu0*rout**(2.-k),size=ntot)/(4*np.pi*nu0),1./(2-k))\n",
    "    phi = np.random.uniform(0.,2*np.pi,ntot)\n",
    "    theta = np.arccos(np.random.uniform(-1,1,ntot))\n",
    "    \n",
    "    x = rho*np.sin(theta)*np.cos(phi)\n",
    "    y = rho*np.sin(theta)*np.sin(phi)\n",
    "    \n",
    "    vobs = np.array([np.random.normal(loc=vmean,scale=np.sqrt(3)*smax/(i**m)) for i in rho])\n",
    "    \n",
    "    if threeD:\n",
    "        z = rho*np.cos(theta)\n",
    "        return pd.DataFrame(np.hstack((x.reshape((ntot,1)),y.reshape((ntot,1)),z.reshape((ntot,1)),\\\n",
    "                                      vobs.reshape((ntot,1)),rho.reshape((ntot,1)))),columns=['x','y','z','vobs','rho'])\n",
    "    else:\n",
    "        r = np.sqrt(np.power(x,2.)+np.power(y,2.))\n",
    "        return pd.DataFrame(np.hstack((r.reshape((ntot,1)),vobs.reshape((ntot,1)))),columns=['r','vobs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "data=pd.read_csv('continuousMock0.csv')\n",
    "\n",
    "def defineAnnuli(r,nAnn):\n",
    "    return np.append(0.,np.sort(r)[np.linspace(0,len(r)-1,nAnn).astype(int)][1:])\n",
    "\n",
    "nAnn = 10\n",
    "annuli = defineAnnuli(data['r'],nAnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelGalaxies(data,annuli):\n",
    "    #adds a column to data indicating the galaxy's membership in an annulus\n",
    "    bla = np.zeros(len(data['r']))\n",
    "    for i in range(len(annuli)-1):\n",
    "        bla += i*np.array(np.logical_and(data['r']>annuli[i],data['r']<=annuli[i+1]).astype(int))\n",
    "    return bla\n",
    "\n",
    "def galInAnn(data,annuli):\n",
    "    #calculates the number of galaxies in all the annuli\n",
    "    return np.array([(data['annuli']==i).sum() for i in range(len(annuli)-1)])\n",
    "\n",
    "def sigInAnn(data,annuli):\n",
    "    return [np.std(data['vobs'][data['annuli']==i],ddof=1) for i in range(len(annuli)-1)]\n",
    "\n",
    "def getProfiles(annuli,rin,rout,nmean,k,smax,m,vmean):\n",
    "    mock = createMockCluster(rin,rout,nmean,k,smax,m,vmean)\n",
    "    mock['annuli'] = labelGalaxies(mock,annuli)\n",
    "    return galInAnn(mock,annuli),sigInAnn(mock,annuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113 112 112 112 113 112 112 112 113] [1533.5686970592865, 1708.8471911765737, 1672.5203324606516, 1657.0006896288683, 1365.0966816840385, 1551.392522463407, 1520.69833183794, 1134.8559673428142, 849.5847196305533]\n"
     ]
    }
   ],
   "source": [
    "data['annuli'] = labelGalaxies(data,annuli)\n",
    "\n",
    "nObs = galInAnn(data,annuli)\n",
    "sObs = sigInAnn(data,annuli)\n",
    "\n",
    "print nObs,sObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all log likelihoods\n",
    "\n",
    "#make a table of log(n!)-s for n=1,...\n",
    "#factorialTable = np.cumsum(np.append(0,[np.log(i) for i in range(1,len(data['r']))]))\n",
    "\n",
    "def logPriorK(k):\n",
    "    #starting gaussian\n",
    "    #nu0 = 3. #mean prior density index\n",
    "    #sigma = 1.\n",
    "    return 0.0\n",
    "    #return -0.5*np.log(2*np.pi*sigma**2)-0.5*(k-nu0)**2/(2*sigma**2)\n",
    "\n",
    "def logPriorM(m):\n",
    "    #starting gaussian\n",
    "    #nu0 = -.2 #mean prior sigma index\n",
    "    #sigma = 0.1\n",
    "    return 0.0\n",
    "    #return -0.5*np.log(2*np.pi*sigma**2)-0.5*(k-nu0)**2/(2*sigma**2)\n",
    "\n",
    "def logPriorSigma0(sigma0):\n",
    "    #starting gaussian\n",
    "    #nu0 = 1000 #mean prior sigma index\n",
    "    #sigma = 500\n",
    "    return 0.0\n",
    "    #return -0.5*np.log(2*np.pi*sigma**2)-0.5*(k-nu0)**2/(2*sigma**2)\n",
    "\n",
    "def logPriorNmean(nmean):\n",
    "    return 0.0\n",
    "\n",
    "def logPriorNtot(ntot):\n",
    "    return 0.0\n",
    "\n",
    "def logLikelihoodNu(prediction,data):\n",
    "    return np.sum(data*np.log(prediction)-prediction)\n",
    "\n",
    "def logLikelihoodSigma(vObs,vPred,nPred):\n",
    "    # distribution of variances is chisq, as shown, for example, at\n",
    "    # https://onlinecourses.science.psu.edu/stat414/node/174\n",
    "    return np.sum(np.log(stats.chi2.pdf((nPred-1.)*np.power(vObs,2.)/np.power(vPred,2.),nPred-1)))\n",
    "\n",
    "def logPosterior(nmean,k,smax,m,annuli,rin,rout,nObs,sObs):\n",
    "    nPred,sPred = getProfiles(annuli,rin,rout,1000*nmean,k,smax,m,0)\n",
    "    nPred/=nmean\n",
    "    return logPriorK(k)+logPriorM(m)+logPriorSigma0(smax)+logPriorNmean(nmean)+\\\n",
    "           logLikelihoodNu(nPred,nObs)+logLikelihoodSigma(sObs,sPred,nPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 99 116 106 111 124 107 104 110 118]\n",
      "[ 51.44193012  52.21131893  52.15547032  50.26068846  48.34638222\n",
      "  45.89147195  43.19688007  39.07649967  30.82787527]\n"
     ]
    }
   ],
   "source": [
    "ntot=1000\n",
    "bla1,bla2 = getProfiles(annuli,1,1000,1000*ntot,3,1000,0.2,0)\n",
    "bla1/=ntot\n",
    "bla2/=np.sqrt(ntot)\n",
    "\n",
    "print bla1\n",
    "print bla2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwalkers = 10\n",
    "ndim = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler = mc.EnsembleSampler(nwalkers, ndim, logPosterior, args=[annuli,rin,rout,nObs,sObs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
