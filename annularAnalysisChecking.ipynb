{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from numba import jit\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 12.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def defineAnnuli(r,nAnn):\n",
    "    return np.append(0.,np.sort(r)[np.linspace(0,len(r)-1,nAnn).astype(int)][1:])\n",
    "\n",
    "@jit\n",
    "def labelGalaxies(data,annuli):\n",
    "    #adds a column to data indicating the galaxy's membership in an annulus\n",
    "    bla = np.zeros(len(data['r']))\n",
    "    for i in range(len(annuli)-1):\n",
    "        bla += i*np.array(np.logical_and(data['r']>annuli[i],data['r']<=annuli[i+1]).astype(int))\n",
    "    return bla\n",
    "\n",
    "def galInAnn(data,annuli):\n",
    "    #calculates the number of galaxies in all the annuli\n",
    "    return np.array([(data['annuli']==i).sum() for i in range(len(annuli)-1)])\n",
    "\n",
    "def sigInAnn(data,annuli):\n",
    "    return [np.std(data['vobs'][data['annuli']==i],ddof=1) for i in range(len(annuli)-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def defineShellRadii(nTot=1000.,rOut=1000.,nAnn=10,k=3):\n",
    "    radii = np.array([1.])\n",
    "    if k==3:\n",
    "        nu0 = nTot/(4*np.pi*np.log(rOut))\n",
    "        c = nTot/(nAnn*4*np.pi*nu0)\n",
    "    else:\n",
    "        nu0 = nTot*(3.-k)/(4*np.pi*(rOut**(3.-k)-1.))\n",
    "        c = (3-k)*nTot/(4*np.pi*nu0*nAnn)\n",
    "        \n",
    "    for i in range(nAnn):\n",
    "        if k==3:\n",
    "            radii = np.append(radii,np.exp(c+np.log(radii[i])))\n",
    "        else:\n",
    "            radii = np.append(radii,(c+radii[i]**(3-k))**(1./(3-k)))\n",
    "    return radii\n",
    "\n",
    "defineShellRadii()\n",
    "\n",
    "@jit\n",
    "def nuProfile(Ntot,radii,k=2.9):\n",
    "    nu0 = Ntot / (4.*np.pi*(nuInt(radii[-1], k)-nuInt(radii[0], k)))\n",
    "    print nu0\n",
    "    #print 'nu0:' ,nu0\n",
    "    return (nu0*(nuInt(radii[1:],k) - nuInt(radii[:-1],k))).astype(int)\n",
    "\n",
    "@jit\n",
    "def sigmaProfile(radii,sigMax=1000,k=-.2):\n",
    "    return sigMax*(0.5*(radii[1:]+radii[:-1]))**k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def createMockData(Ntot=1000,rOut=1000.,nAnn=10,sigMax=1000,kindex=3.,sigmaindex=-0.2): #total Ngals, no of shells\n",
    "    clusterData = np.zeros((2*Ntot,2))\n",
    "    counter=0\n",
    "    radii = defineShellRadii(Ntot,rOut,nAnn,kindex)\n",
    "    #density = nuProfile(Ntot,radii,k=kindex)\n",
    "    sig = sigmaProfile(radii,sigMax,k=sigmaindex)\n",
    "    \n",
    "    for shell,dens in enumerate(np.random.poisson(Ntot/nAnn*np.ones(nAnn))):\n",
    "        #generate positions\n",
    "        phi = np.random.uniform(0.,2*np.pi,dens)\n",
    "        theta = np.arccos(np.random.uniform(-1,1,dens))\n",
    "        r = np.power(np.random.uniform(radii[shell]**3,radii[shell+1]**3,dens),1./3)\n",
    "        \n",
    "        x = r*np.sin(theta)*np.cos(phi)\n",
    "        y = r*np.sin(theta)*np.sin(phi)\n",
    "        #z = r*cosTheta\n",
    "        \n",
    "        radius = np.sqrt(np.power(x,2.)+np.power(y,2.))\n",
    "        #generate velocities\n",
    "                \n",
    "        v=sig[shell]*np.random.randn(dens)*np.random.uniform(-1,1,dens)\n",
    "        \n",
    "        #replace with vstack,append\n",
    "        clusterData[counter:counter+dens]=np.hstack((radius.reshape((dens,1)),v.reshape((dens,1))))\n",
    "        counter += dens\n",
    "    \n",
    "    #print 'Created mock data with '+str(counter)+' galaxies.'\n",
    "    return pd.DataFrame(clusterData[:counter],columns=['r','vobs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68 67 67 68 67 67 67 68 67 67 67 68 67 67 68] [64.14120369251789, 69.98383527188948, 51.70161106854093, 52.21401782602426, 61.5454999928081, 56.93241181829846, 45.695058924325764, 50.97316434769666, 50.430227270852505, 37.94624903461398, 33.04350881685686, 43.40570583889496, 31.63074066305707, 35.5420446499, 42.60270965636823]\n"
     ]
    }
   ],
   "source": [
    "ntot = 1000\n",
    "rout = 1000\n",
    "nshells = 7\n",
    "sigMax = 500\n",
    "kInd = 2.\n",
    "sigInd = -0.3\n",
    "\n",
    "data = createMockData(ntot,rout,nshells,sigMax,kInd,sigInd)\n",
    "\n",
    "nAnn = 15 #number of desired annuli\n",
    "annuli = defineAnnuli(data['r'],nAnn+1)\n",
    "\n",
    "data['annuli']=labelGalaxies(data,annuli)\n",
    "nData = galInAnn(data,annuli)\n",
    "sigmaData = sigInAnn(data,annuli)\n",
    "\n",
    "print nData,sigmaData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all log likelihoods\n",
    "\n",
    "#make a table of log(n!)-s for n=1,...\n",
    "factorialTable = np.cumsum(np.append(0,[np.log(i) for i in range(1,len(data['r']))]))\n",
    "\n",
    "def logPriorNu(k):\n",
    "    #starting gaussian\n",
    "    nu0 = 3. #mean prior density index\n",
    "    sigma = 30.\n",
    "    return 0\n",
    "    #return -0.5*np.log(2*np.pi*sigma**2)-0.5*(k-nu0)**2/(2*sigma**2)\n",
    "\n",
    "def logPriorSigma(k):\n",
    "    #starting gaussian\n",
    "    nu0 = -.2 #mean prior sigma index\n",
    "    sigma = 3.\n",
    "    return 0.\n",
    "    #return -0.5*np.log(2*np.pi*sigma**2)-0.5*(k-nu0)**2/(2*sigma**2)\n",
    "\n",
    "def logPriorSigmaNorm(k):\n",
    "    #starting gaussian\n",
    "    nu0 = 1000 #mean prior sigma index\n",
    "    sigma = 1000\n",
    "    return 0.\n",
    "    #return -0.5*np.log(2*np.pi*sigma**2)-0.5*(k-nu0)**2/(2*sigma**2)\n",
    "\n",
    "def logLikelihoodNu(prediction,data):\n",
    "    return np.sum(data*np.log(prediction)-prediction-factorialTable[data])\n",
    "\n",
    "def logLikelihoodSigma(vObs,vPred,nPred):\n",
    "    # distribution of variances is chisq, as shown, for example, at\n",
    "    # https://onlinecourses.science.psu.edu/stat414/node/174\n",
    "    return np.sum(np.log(stats.chi2.pdf((nPred-1.)*np.power(vObs,2.)/np.power(vPred,2.),nPred-1)))\n",
    "\n",
    "def logPosterior(vObs,vPred,nObs,nPred,kInd,sigmaInd,sigmaNorm):\n",
    "    return logPriorNu(kInd)+logPriorSigma(sigmaInd)+logPriorSigmaNorm(sigmaNorm)+\\\n",
    "           logLikelihoodNu(nPred,nObs)+logLikelihoodSigma(vObs,vPred,nPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def mcmcStep(annuli,kInd,sInd,sigMax):\n",
    "    mockData = createMockData(len(data['r']),np.amax(data['r']),nshells,sigMax,kInd,sigInd)\n",
    "    mockData['annuli'] = labelGalaxies(mockData,annuli)\n",
    "    return galInAnn(mockData,annuli),sigInAnn(mockData,annuli)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 92.92 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1 loops, best of 3: 29.3 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mcmcStep(annuli,kInd,sigInd,sigMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateMeanMock(annuli,kInd,sInd,sMaxInd):\n",
    "    while True:\n",
    "        dens,sig = mcmcStep(annuli,kInd,sigInd,sigMax)\n",
    "        if np.isnan(sig).any():\n",
    "            continue\n",
    "        else:\n",
    "            #print dens,sig\n",
    "            break\n",
    "    \n",
    "    while True:\n",
    "        hlp1,hlp2 = mcmcStep(annuli,kInd,sigInd,sigMax)\n",
    "        if np.isnan(hlp2).any():\n",
    "            continue\n",
    "        else:\n",
    "            #print hlp1,hlp2\n",
    "            dens,sig = np.vstack((dens,hlp1)),np.vstack((sig,hlp2))\n",
    "        if dens.shape[0]>15:\n",
    "            break\n",
    "        \n",
    "    return np.mean(dens,axis=0),np.mean(sig,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 479 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "bla1,bla2 = generateMeanMock(annuli,a,b,sigMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kInd = 1.9\n",
      "kInd = 1.90512820513\n",
      "kInd = 1.91025641026\n",
      "kInd = 1.91538461538\n",
      "kInd = 1.92051282051"
     ]
    }
   ],
   "source": [
    "# Set up parameter grids:\n",
    "npix = 40\n",
    "amin,amax = 1.9,2.1\n",
    "bmin,bmax = -5.,4.\n",
    "agrid = np.linspace(amin,amax,npix)\n",
    "bgrid = np.linspace(bmin,bmax,npix)\n",
    "logprob = np.zeros([npix,npix])\n",
    "\n",
    "# Loop over parameters, computing unnormlized log posterior PDF:\n",
    "for i,a in enumerate(agrid):\n",
    "    print 'kInd = '+str(a)\n",
    "    for j,b in enumerate(bgrid):\n",
    "        #print 'kInd,sigInd = '+str(a)+','+str(b)\n",
    "        nPred,sigPred = generateMeanMock(annuli,a,b,sigMax)\n",
    "        logprob[j,i] = logPosterior(sigmaData,sigPred,nData,nPred,a,b,sigMax)\n",
    "\n",
    "# Normalize and exponentiate to get posterior density:\n",
    "Z = np.max(logprob)\n",
    "prob = np.exp(logprob - Z)\n",
    "norm = np.sum(prob)\n",
    "prob /= norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted = np.sort(prob.flatten())\n",
    "C = sorted.cumsum()\n",
    "\n",
    "# Find the pixel values that lie at the levels that contain\n",
    "# 68% and 95% of the probability:\n",
    "lvl68 = np.min(sorted[C > (1.0 - 0.68)])\n",
    "lvl95 = np.min(sorted[C > (1.0 - 0.95)])\n",
    "\n",
    "plt.imshow(prob, origin='lower', cmap='Blues', interpolation='none') #,extent=[amin,amax,bmin,bmax])\n",
    "plt.contour(prob,[lvl68,lvl95],colors='black',extent=[amin,amax,bmin,bmax])\n",
    "plt.grid()\n",
    "plt.xlabel('density index')\n",
    "plt.ylabel('sigma index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_kInd_given_data = np.sum(prob,axis=0) # Approximate the integral as a sum\n",
    "prob_sigmaInd_given_data = np.sum(prob,axis=1) # Approximate the integral as a sum\n",
    "\n",
    "fig,ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_size_inches(15, 6)\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "left = ax[0].plot(agrid, prob_kInd_given_data)\n",
    "ax[0].set_title('${\\\\rm Pr}(kInd|d)$')\n",
    "ax[0].set_xlabel('galaxy density slope')\n",
    "ax[0].set_ylabel('Posterior probability density')\n",
    "\n",
    "right = ax[1].plot(bgrid, prob_sigmaInd_given_data)\n",
    "ax[1].set_title('${\\\\rm Pr}(sigmaInd|d)$')\n",
    "ax[0].set_xlabel('velocity spread slope')\n",
    "ax[1].set_ylabel('Posterior probability density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compress_1D_pdf(x,pr,ci=68,dp=1):\n",
    "    \n",
    "    # Interpret credible interval request:\n",
    "    low  = (1.0 - ci/100.0)/2.0    # 0.16 for ci=68\n",
    "    high = 1.0 - low               # 0.84 for ci=68\n",
    "\n",
    "    # Find cumulative distribution and compute percentiles:\n",
    "    cumulant = pr.cumsum()\n",
    "    pctlow = x[cumulant>low].min()\n",
    "    median = x[cumulant>0.50].min()\n",
    "    pcthigh = x[cumulant>high].min()\n",
    "    \n",
    "    # Convert to error bars, and format a string:\n",
    "    errplus = np.abs(pcthigh - median)\n",
    "    errminus = np.abs(median - pctlow)\n",
    "    \n",
    "    report = \"$ \"+str(round(median,dp))+\"^{+\"+str(round(errplus,dp))+\"}_{-\"+str(round(errminus,dp))+\"} $\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "print(\"kInd = \",compress_1D_pdf(agrid,prob_kInd_given_data,ci=68,dp=2))\n",
    "\n",
    "print(\"sigmaInd = \",compress_1D_pdf(bgrid,prob_sigmaInd_given_data,ci=68,dp=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
